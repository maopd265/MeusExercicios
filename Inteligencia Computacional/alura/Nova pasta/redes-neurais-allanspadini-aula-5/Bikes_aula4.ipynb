{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A base de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dados = pd.read_csv('Bicicletas.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conhecendo a base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.scatter(dados['temperatura'],dados['bicicletas_alugadas'])\n",
    "plt.ylabel('bicicletas_alugadas')\n",
    "plt.xlabel('temperatura')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(dados['clima'],dados['bicicletas_alugadas'])\n",
    "plt.ylabel('bicicletas_alugadas')\n",
    "plt.xlabel('clima')\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "indice=[1,2,3]\n",
    "plt.xticks(indice, fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizando a base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dados['bicicletas_alugadas'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dados[['clima','temperatura']].values\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/np.amax(X,axis=0)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ymax=np.amax(y)\n",
    "y = y/ymax\n",
    "print(y[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções de ativação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Soma):\n",
    "    return 1/(1+np.exp(-Soma))\n",
    "\n",
    "def relu(Soma):\n",
    "    return np.maximum(0,Soma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando a estrutura da rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquitetura = [\n",
    "    {\"dim_entrada\": 2, \"dim_saida\": 50, \"ativacao\": \"relu\"},\n",
    "    {\"dim_entrada\": 50, \"dim_saida\": 1, \"ativacao\": \"sigmoid\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pesos e viés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inicia_camadas(arquitetura, seed = 99):\n",
    "    # inicia os valores aleatórios\n",
    "    np.random.seed(seed)\n",
    "    # numero de camadas da rede neural\n",
    "    numero_de_camadas = len(arquitetura)\n",
    "    # inicia armazenamento de parametros\n",
    "    valores_parametros = {}\n",
    "    \n",
    "    # itera nas camadas da rede\n",
    "    for indice, camada in enumerate(arquitetura):\n",
    "        \n",
    "        indice_camada = indice + 1\n",
    "        \n",
    "        # extrai o numero de nodos nas camadas\n",
    "        tamanho_camada_entrada = camada[\"dim_entrada\"]\n",
    "        tamanho_camada_saida = camada[\"dim_saida\"]\n",
    "        \n",
    "        # inicia os valores na matriz de pesos P\n",
    "        # e o vetor de viés ou bias b\n",
    "        valores_parametros['P' + str(indice_camada)] = np.random.randn(\n",
    "            tamanho_camada_saida, tamanho_camada_entrada)  * 0.1\n",
    "        valores_parametros['b' + str(indice_camada)] = np.random.randn(\n",
    "            tamanho_camada_saida, 1) * 0.1\n",
    "        \n",
    "    return valores_parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propagação da rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propaga_uma_camada(Ativado_anterior, Pesos_atual, b_atual, ativacao=\"relu\"):\n",
    "    # cálculo da entrada para a função de ativação\n",
    "    Saida_atual = np.dot(Pesos_atual, Ativado_anterior) + b_atual\n",
    "    \n",
    "    # selecção da função de ativação\n",
    "    if ativacao is \"relu\":\n",
    "        func_ativacao = relu\n",
    "    elif ativacao is \"sigmoid\":\n",
    "        func_ativacao = sigmoid\n",
    "    else:\n",
    "        raise Exception('Ainda não implementamos essa funcao')\n",
    "        \n",
    "    # retorna a ativação calculada Ativado_atual e a matriz intermediária Saida\n",
    "    return func_ativacao(Saida_atual), Saida_atual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propaga_total(X, valores_parametros, arquitetura):\n",
    "    # memoria temporaria para a retropropagacao\n",
    "    memoria = {}\n",
    "    # O vetor X é a ativação para a camada 0 \n",
    "    Ativado_atual = X\n",
    "    \n",
    "    # iterações para as camadas\n",
    "    for indice, camada in enumerate(arquitetura):\n",
    "        # a numeração das camadas começa de 1\n",
    "        indice_camada = indice + 1\n",
    "        # utiliza a ativação da iteração anterior\n",
    "        Ativado_anterior = Ativado_atual\n",
    "        \n",
    "        # extrai a função de ativação para a camada atual\n",
    "        func_ativacao_atual = camada[\"ativacao\"]\n",
    "        # extrai os pesos da camada atual\n",
    "        Pesos_atual = valores_parametros[\"P\" + str(indice_camada)]\n",
    "        # extrai o bias para a camada atual\n",
    "        b_atual = valores_parametros[\"b\" + str(indice_camada)]\n",
    "        # cálculo da ativação para a camada atual\n",
    "        Ativado_atual, Saida_atual = propaga_uma_camada(Ativado_anterior, Pesos_atual, b_atual, func_ativacao_atual)\n",
    "        \n",
    "        # salca os valores calculados na memória\n",
    "        memoria[\"A\" + str(indice)] = Ativado_anterior\n",
    "        memoria[\"Z\" + str(indice_camada)] = Saida_atual\n",
    "       \n",
    "    # retorna o vetor predito e um dicionário contendo os valores intermediários\n",
    "    return Ativado_atual, memoria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testando a rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_parametros = inicia_camadas(arquitetura, seed = 99)\n",
    "y_estimado, memoria = propaga_total(np.transpose(X), valores_parametros, arquitetura)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_estimado[0,0]*ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]*ymax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atualização dos pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atualiza(valores_parametros, gradidentes, arquitetura, taxa_aprendizagem):\n",
    "\n",
    "    # iterações pelas camadas\n",
    "    for indice_camada, camada in enumerate(arquitetura, 1):\n",
    "        valores_parametros[\"P\" + str(indice_camada)] -= taxa_aprendizagem * gradidentes[\"dP\" + str(indice_camada)]        \n",
    "        valores_parametros[\"b\" + str(indice_camada)] -= taxa_aprendizagem * gradidentes[\"db\" + str(indice_camada)]\n",
    "\n",
    "    return valores_parametros;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de custo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valor_de_custo(Y_predito, Y):\n",
    "    # numero_de_exemplos\n",
    "    m = Y_predito.shape[1]\n",
    "    \n",
    "    custo = -1 / m * (np.dot(Y, np.log(Y_predito).T) + np.dot(1 - Y, np.log(1 - Y_predito).T))\n",
    "    return np.squeeze(custo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retropropagação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retropropagacao_total(Y_predito, Y, memoria, valores_parametros, arquitetura):\n",
    "   \n",
    "    gradientes = {}\n",
    "    \n",
    "    # numero de exemplos\n",
    "    #m = Y.shape[1]\n",
    "    # para garantir que os dois vetores tenham a mesma dimensão\n",
    "    Y = Y.reshape(Y_predito.shape)\n",
    "    \n",
    "    # inicia o algoritmo de gradiente descendente\n",
    "    dAtivado_anterior = - (np.divide(Y, Y_predito) - np.divide(1 - Y, 1 - Y_predito));\n",
    "    \n",
    "    for indice_camada_anterior, camada in reversed(list(enumerate(arquitetura))):\n",
    "        \n",
    "        indice_camada_atual = indice_camada_anterior + 1\n",
    "        # Função de ativação para a camada atual\n",
    "        \n",
    "        funcao_ativao_atual = camada[\"ativacao\"]\n",
    "        \n",
    "        dAtivado_atual = dAtivado_anterior\n",
    "        \n",
    "        Ativado_anterior = memoria[\"A\" + str(indice_camada_anterior)]\n",
    "        Saida_atual = memoria[\"Z\" + str(indice_camada_atual)]\n",
    "        \n",
    "        Pesos_atual = valores_parametros[\"P\" + str(indice_camada_atual)]\n",
    "        b_atual = valores_parametros[\"b\" + str(indice_camada_atual)]\n",
    "        \n",
    "        dAtivado_anterior, dPesos_atual, db_atual = retropropagacao_uma_camada(\n",
    "            dAtivado_atual, Pesos_atual, b_atual, Saida_atual, Ativado_anterior, funcao_ativao_atual)\n",
    "        \n",
    "        gradientes[\"dP\" + str(indice_camada_atual)] = dPesos_atual\n",
    "        gradientes[\"db\" + str(indice_camada_atual)] = db_atual\n",
    "    \n",
    "    return gradientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_retro(dAtivado, Saida):\n",
    "    sig = sigmoid(Saida)\n",
    "    return dAtivado * sig * (1 - sig)\n",
    "\n",
    "def relu_retro(dAtivado, Saida):\n",
    "    dSaida = np.array(dAtivado, copy = True)\n",
    "    dSaida[Saida <= 0] = 0;\n",
    "    return dSaida;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retropropagacao_uma_camada(dAtivado_atual, Pesos_atual, b_atual, Saida_atual, Ativado_anterior, ativacao=\"relu\"):\n",
    "    # número de exemplos\n",
    "    m = Ativado_anterior.shape[1]\n",
    "    \n",
    "    # seleção função de ativação\n",
    "    if ativacao is \"relu\":\n",
    "        func_ativacao_retro = relu_retro\n",
    "    elif ativacao is \"sigmoid\":\n",
    "        func_ativacao_retro = sigmoid_retro\n",
    "    else:\n",
    "        raise Exception('Ainda não implementamos essa funcao')\n",
    "    \n",
    "    # derivada da função de ativação\n",
    "    dSaida_atual = func_ativacao_retro(dAtivado_atual, Saida_atual)\n",
    "    \n",
    "    # derivada da matriz de Pesos\n",
    "    dPesos_atual = np.dot(dSaida_atual, Ativado_anterior.T) / m\n",
    "    # derivada do vetor b\n",
    "    db_atual = np.sum(dSaida_atual, axis=1, keepdims=True) / m\n",
    "    # derivada da matriz A_anterior\n",
    "    dAtivado_anterior = np.dot(Pesos_atual.T, dSaida_atual)\n",
    "\n",
    "    return dAtivado_anterior, dPesos_atual, db_atual"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
